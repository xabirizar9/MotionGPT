{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import your data loading utilities and model\n",
    "from mGPT.data.build_data import build_data\n",
    "from mGPT.models.build_model import build_model\n",
    "from mGPT.archs.mgpt_vq import VQVae\n",
    "from mGPT.config import get_module_config\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config files in the same way as parse_args()\n",
    "OmegaConf.register_new_resolver(\"eval\", eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full config...\n"
     ]
    }
   ],
   "source": [
    "cfg_assets = OmegaConf.load('./configs/assets.yaml')\n",
    "cfg_base = OmegaConf.load(os.path.join(cfg_assets.CONFIG_FOLDER, 'default.yaml'))\n",
    "cfg_exp = OmegaConf.merge(cfg_base, OmegaConf.load('configs/codebook_experiments/config_h3d_stage1.yaml'))\n",
    "\n",
    "# Load module configs if not full config\n",
    "if not cfg_exp.FULL_CONFIG:\n",
    "    print(\"Loading full config...\")\n",
    "    cfg_exp = get_module_config(cfg_exp, cfg_assets.CONFIG_FOLDER)\n",
    "\n",
    "# Merge with assets config which contains the dataset paths\n",
    "cfg = OmegaConf.merge(cfg_exp, cfg_assets)\n",
    "\n",
    "# Override some config values for testing\n",
    "cfg.TRAIN.BATCH_SIZE = 32\n",
    "cfg.TRAIN.NUM_WORKERS = 2\n",
    "cfg.DEBUG = False\n",
    "cfg.DEVICE = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "cfg.TRAIN.PRETRAINED = 'experiments/mgpt/Codebook_VQVAE_Usage/checkpoints/epoch=9.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mGPT.data.HumanML3D HumanML3DDataModule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7cc1880cc44389995921239c75bae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c71988af6374e489f2b8ba351053d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize data and model\n",
    "datamodule = build_data(cfg)\n",
    "datamodule.setup('fit')  # Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from:  experiments/mgpt/Codebook_VQVAE_Usage/checkpoints/epoch=9.ckpt\n",
      "\n",
      "Original keys containing 'codebook':\n",
      "['vae.quantizer.codebook']\n",
      "\n",
      "Mapped keys containing 'codebook':\n",
      "['quantizer.codebook']\n"
     ]
    }
   ],
   "source": [
    "vqvae = VQVae(\n",
    "    nfeats=263,\n",
    "    code_num=512,\n",
    "    code_dim=512,\n",
    "    output_emb_width=512,\n",
    "    down_t=2,\n",
    "    stride_t=2,\n",
    "    width=512,\n",
    "    depth=3,\n",
    "    dilation_growth_rate=3,\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "# Load pretrained weights with proper key matching\n",
    "# Load pretrained weights with proper key matching\n",
    "if cfg.TRAIN.PRETRAINED:\n",
    "    print(\"Loading pretrained weights from: \", cfg.TRAIN.PRETRAINED)\n",
    "    state_dict = torch.load(cfg.TRAIN.PRETRAINED, map_location='cpu')['state_dict']\n",
    "    \n",
    "    # Debug: Print original keys\n",
    "    print(\"\\nOriginal keys containing 'codebook':\")\n",
    "    codebook_keys = [k for k in state_dict.keys() if 'codebook' in k]\n",
    "    print(codebook_keys)\n",
    "    \n",
    "    # Create a new state dict with correct keys\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        # Handle both 'motion_vae.' and 'vae.' prefixes\n",
    "        if k.startswith('motion_vae.'):\n",
    "            new_key = k.replace('motion_vae.', '')\n",
    "            new_state_dict[new_key] = v\n",
    "        elif k.startswith('vae.'):\n",
    "            new_key = k.replace('vae.', '')\n",
    "            new_state_dict[new_key] = v\n",
    "    \n",
    "    # Debug: Print new keys\n",
    "    print(\"\\nMapped keys containing 'codebook':\")\n",
    "    new_codebook_keys = [k for k in new_state_dict.keys() if 'codebook' in k]\n",
    "    print(new_codebook_keys)\n",
    "    \n",
    "    # Try loading with strict=False first to see what matches\n",
    "    incompatible_keys = vqvae.load_state_dict(new_state_dict, strict=False)\n",
    "    vqvae.to('cuda')\n",
    "    vqvae.training = False\n",
    "    vqvae.quantizer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a small subset of data\n",
    "train_loader = datamodule.train_dataloader()\n",
    "eval_batch = next(iter(train_loader))  # Get just one batch\n",
    "eval_batch['motion'] = eval_batch['motion'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-9.8387e-03, -3.3771e-01, -5.2731e+00,  ...,  4.2882e+00,\n",
       "            5.2595e+00,  4.5748e+00],\n",
       "          [ 4.9087e-02, -1.7745e-01, -9.3925e+00,  ...,  7.8541e+00,\n",
       "            8.6929e+00,  7.9850e+00],\n",
       "          [-9.1842e-02, -7.2390e-02, -1.1847e+01,  ...,  9.7935e+00,\n",
       "            1.0588e+01,  9.6801e+00],\n",
       "          ...,\n",
       "          [-6.2316e-02, -6.0175e-02, -1.1515e+01,  ...,  9.8404e+00,\n",
       "            1.0355e+01,  9.3999e+00],\n",
       "          [ 2.6104e-02,  6.5609e-02, -9.0484e+00,  ...,  7.9223e+00,\n",
       "            8.3383e+00,  7.6678e+00],\n",
       "          [-9.7985e-02,  2.8476e-01, -5.1183e+00,  ...,  4.7841e+00,\n",
       "            4.5934e+00,  4.3042e+00]],\n",
       " \n",
       "         [[ 1.5146e-02, -3.5860e-01, -5.0380e+00,  ...,  4.2354e+00,\n",
       "            5.4761e+00,  4.7863e+00],\n",
       "          [ 6.6775e-02, -2.4182e-01, -9.0430e+00,  ...,  7.7067e+00,\n",
       "            9.1282e+00,  8.3848e+00],\n",
       "          [-5.6464e-02, -1.7559e-01, -1.1417e+01,  ...,  9.6067e+00,\n",
       "            1.1170e+01,  1.0240e+01],\n",
       "          ...,\n",
       "          [-6.5343e-02, -5.0021e-02, -1.1615e+01,  ...,  9.8801e+00,\n",
       "            1.0722e+01,  9.7571e+00],\n",
       "          [ 1.7392e-02,  8.2447e-02, -9.1333e+00,  ...,  7.9563e+00,\n",
       "            8.6052e+00,  7.9125e+00],\n",
       "          [-1.1255e-01,  2.9546e-01, -5.1901e+00,  ...,  4.8094e+00,\n",
       "            4.7256e+00,  4.4270e+00]],\n",
       " \n",
       "         [[ 1.4996e-02, -3.5960e-01, -4.9881e+00,  ...,  4.2141e+00,\n",
       "            5.4557e+00,  4.7633e+00],\n",
       "          [ 6.9224e-02, -2.4482e-01, -8.9583e+00,  ...,  7.6659e+00,\n",
       "            9.0920e+00,  8.3453e+00],\n",
       "          [-5.3397e-02, -1.7899e-01, -1.1310e+01,  ...,  9.5557e+00,\n",
       "            1.1127e+01,  1.0197e+01],\n",
       "          ...,\n",
       "          [-6.4323e-02, -4.9772e-02, -1.1543e+01,  ...,  9.8046e+00,\n",
       "            1.0641e+01,  9.6847e+00],\n",
       "          [ 1.6920e-02,  8.1364e-02, -9.0788e+00,  ...,  7.8979e+00,\n",
       "            8.5423e+00,  7.8546e+00],\n",
       "          [-1.1222e-01,  2.9270e-01, -5.1611e+00,  ...,  4.7742e+00,\n",
       "            4.6921e+00,  4.3956e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.3523e-03, -3.3232e-01, -5.0520e+00,  ...,  4.1744e+00,\n",
       "            5.2970e+00,  4.6181e+00],\n",
       "          [ 5.7561e-02, -1.9609e-01, -9.0577e+00,  ...,  7.5991e+00,\n",
       "            8.8040e+00,  8.0776e+00],\n",
       "          [-7.0650e-02, -1.0983e-01, -1.1443e+01,  ...,  9.4796e+00,\n",
       "            1.0743e+01,  9.8371e+00],\n",
       "          ...,\n",
       "          [-6.1013e-02, -4.2176e-02, -1.1364e+01,  ...,  9.7258e+00,\n",
       "            1.0584e+01,  9.6419e+00],\n",
       "          [ 1.4639e-02,  8.3926e-02, -8.9374e+00,  ...,  7.8341e+00,\n",
       "            8.4835e+00,  7.8058e+00],\n",
       "          [-1.1361e-01,  2.9009e-01, -5.0858e+00,  ...,  4.7351e+00,\n",
       "            4.6513e+00,  4.3628e+00]],\n",
       " \n",
       "         [[ 1.7719e-01, -7.5279e-01,  3.5182e+00,  ..., -1.2832e+00,\n",
       "            4.4879e+00,  3.8059e+00],\n",
       "          [ 9.4271e-02, -4.8416e-01,  6.4568e+00,  ..., -1.9532e+00,\n",
       "            7.5830e+00,  7.0650e+00],\n",
       "          [ 1.3386e-01,  1.9028e-01,  8.2731e+00,  ..., -2.4113e+00,\n",
       "            9.3845e+00,  9.0104e+00],\n",
       "          ...,\n",
       "          [-2.1635e-01,  2.8230e-02,  8.0088e+00,  ...,  1.0571e+01,\n",
       "           -1.8790e+00, -1.7165e+00],\n",
       "          [-1.3140e-01, -5.5474e-01,  6.0628e+00,  ...,  8.4172e+00,\n",
       "           -1.2101e+00, -1.0591e+00],\n",
       "          [ 6.9889e-02, -4.2214e-01,  3.4502e+00,  ...,  4.9786e+00,\n",
       "           -5.5573e-01, -3.3376e-01]],\n",
       " \n",
       "         [[-4.0317e-01,  7.1968e-01,  3.6371e+00,  ...,  3.7159e+00,\n",
       "            2.6097e-02, -5.3273e-01],\n",
       "          [-3.9816e-01,  7.8234e-01,  7.1244e+00,  ...,  7.7880e+00,\n",
       "           -1.1420e+00, -1.2125e+00],\n",
       "          [-4.5838e-01,  5.3697e-01,  9.7815e+00,  ...,  1.0689e+01,\n",
       "           -2.0403e+00, -2.1719e+00],\n",
       "          ...,\n",
       "          [-3.8835e-02, -1.0881e-01, -1.0068e+01,  ...,  9.8506e+00,\n",
       "            9.8491e+00,  9.0301e+00],\n",
       "          [ 4.1340e-02,  3.8346e-03, -7.8513e+00,  ...,  7.9037e+00,\n",
       "            7.9011e+00,  7.3632e+00],\n",
       "          [-6.9475e-02,  2.5914e-01, -4.3901e+00,  ...,  4.7549e+00,\n",
       "            4.3121e+00,  4.1269e+00]]], device='cuda:0',\n",
       "        grad_fn=<PermuteBackward0>),\n",
       " tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(40.3889, device='cuda:0'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqvae(eval_batch['motion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tokens = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n",
      "63.671875\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batches = 0\n",
    "    for batch in train_loader:\n",
    "        batches += 1\n",
    "        codes, _ = vqvae.encode(batch['motion'].to('cuda'))\n",
    "        seen_tokens.update(codes.flatten().cpu().numpy())\n",
    "        # codes = vqvae(batch['motion'].to('cuda'))\n",
    "print(batches)\n",
    "print(len(seen_tokens)/512*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        x_r, loss, perplexity = vqvae(batch['motion'].to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/unique_tokens': 339,\n",
       " 'val/total_tokens': 1296704,\n",
       " 'val/codebook_usage_percent': 66.2109375}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqvae.quantizer.get_token_usage_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seen_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = vqvae.quantizer.get_token_usage_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = stats['val/token_frequencies'].cpu().numpy()\n",
    "\n",
    "threshold = 600\n",
    "mean_freq = np.mean(freqs)\n",
    "freqs = freqs[freqs > threshold]\n",
    "\n",
    "print(\"mean freq: \", mean_freq)\n",
    "print(f\"Usage percentage: {(len(freqs) / 512)*100: .2f}%\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(freqs)), freqs[freqs > threshold])\n",
    "plt.title('Codebook Usage Distribution')\n",
    "plt.xlabel('Codebook Index (sorted by usage)')\n",
    "plt.ylabel('Usage Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze codebook usage\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    print(\"Input shape: \", eval_batch['motion'].shape)\n",
    "    x_out, loss, perplexity = vqvae(eval_batch['motion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
